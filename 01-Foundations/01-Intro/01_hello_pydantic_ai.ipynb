{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic AI: A Powerful Tool for Data Validation and Parsing\n",
    "\n",
    "- Pydantic AI is a library that leverages Python's type annotations to provide data validation and parsing capabilities.\n",
    "- It is built on top of Pydantic, a popular data validation library, and extends its functionality with AI-powered features.\n",
    "- Pydantic AI allows developers to define data models using Python classes and type hints, making it easy to validate and parse complex data structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de09b765-c7f8-4ed7-be56-21d3323e4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from unittest import result\n",
    "from ollama import Client\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent\n",
    "from rich import print\n",
    "import logfire\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LOGFIRE_API_KEY = os.getenv(\"LOGFIRE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a40cb5-12e1-4f92-822f-96b4e342aa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=589460;https://logfire-us.pydantic.dev/jimbmour/starter-project\u001b\\\u001b[4;36mhttps://logfire-us.pydantic.dev/jimbmour/starter-project\u001b[0m\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "# Logfire helps you monitor and debug your Pydantic AI applications.\n",
    "# It's optional but highly recommended for production use.\n",
    "# You can sign up for a free account at https://logfire.dev and get your token\n",
    "logfire.configure(token=LOGFIRE_API_KEY)  \n",
    "logfire.instrument_pydantic_ai()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Simple Agent with Pydantic AI\n",
    "\n",
    "- Pydantic AI makes it easy to create agents that can interact with language models and parse unstructured text into structured data.\n",
    "\n",
    "### OpenAI Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75aa4fce-9ac9-4a29-a859-84b5bbe0a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05:49:56.794 agent run\n",
      "05:49:56.795   chat gpt-5-nano\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Nice to meet you, Alice! Thanks for sharing a bit about you.\n",
       "\n",
       "How can I help today? Here are a few things I can assist with, and you can tell me what you’re aiming for:\n",
       "\n",
       "- Coding help: debugging, algorithm practice, or code reviews <span style=\"font-weight: bold\">(</span>in Python/JavaScript/Java/C++, etc.<span style=\"font-weight: bold\">)</span>\n",
       "- Learning plan: pick a language or framework and I’ll lay out a <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>-week path\n",
       "- Interview prep or career guidance: practice questions, mock interviews, resume/portfolio tips\n",
       "- Productivity and career growth: career roadmap to senior/lead roles, time management, best practices\n",
       "- Personal topics: work-life balance, debugging mental models, or design/system thinking\n",
       "\n",
       "If you’d like, tell me your current goal <span style=\"font-weight: bold\">(</span>e.g., “prepare for a System Design interview,” or “improve React \n",
       "skills”<span style=\"font-weight: bold\">)</span>, or I can start with a quick coding problem.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Nice to meet you, Alice! Thanks for sharing a bit about you.\n",
       "\n",
       "How can I help today? Here are a few things I can assist with, and you can tell me what you’re aiming for:\n",
       "\n",
       "- Coding help: debugging, algorithm practice, or code reviews \u001b[1m(\u001b[0min Python/JavaScript/Java/C++, etc.\u001b[1m)\u001b[0m\n",
       "- Learning plan: pick a language or framework and I’ll lay out a \u001b[1;36m4\u001b[0m-week path\n",
       "- Interview prep or career guidance: practice questions, mock interviews, resume/portfolio tips\n",
       "- Productivity and career growth: career roadmap to senior/lead roles, time management, best practices\n",
       "- Personal topics: work-life balance, debugging mental models, or design/system thinking\n",
       "\n",
       "If you’d like, tell me your current goal \u001b[1m(\u001b[0me.g., “prepare for a System Design interview,” or “improve React \n",
       "skills”\u001b[1m)\u001b[0m, or I can start with a quick coding problem.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunUsage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">input_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, <span style=\"color: #808000; text-decoration-color: #808000\">output_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">765</span>, <span style=\"color: #808000; text-decoration-color: #808000\">details</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'accepted_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'audio_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rejected_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">requests</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mRunUsage\u001b[0m\u001b[1m(\u001b[0m\u001b[33minput_tokens\u001b[0m=\u001b[1;36m27\u001b[0m, \u001b[33moutput_tokens\u001b[0m=\u001b[1;36m765\u001b[0m, \u001b[33mdetails\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'accepted_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'audio_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m, \n",
       "\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m576\u001b[0m, \u001b[32m'rejected_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mrequests\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 2. Create an Agent with Pydantic AI ---\n",
    "# An Agent is the core of Pydantic AI. It combines your data model with\n",
    "# the LLM to extract structured data from unstructured text.\n",
    "# Here, we create an agent that uses the Ollama LLM via the OllamaTool\n",
    "model = OpenAIChatModel(\"gpt-5-nano\", provider=OpenAIProvider(api_key=OPENAI_API_KEY))\n",
    "agent = Agent(model)\n",
    "\n",
    "# when running in a script, use asyncio.run(main())\n",
    "result = await agent.run(\n",
    "    \"Hello, my name is Alice. I am 30 years old and I work as a software engineer.\"\n",
    ")\n",
    "print(result.output)\n",
    "\n",
    "print(result.usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenRouter Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why do programmers prefer dark mode?\n",
       "\n",
       "Because light attracts bugs!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why do programmers prefer dark mode?\n",
       "\n",
       "Because light attracts bugs!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunUsage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">input_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #808000; text-decoration-color: #808000\">output_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>, <span style=\"color: #808000; text-decoration-color: #808000\">details</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'image_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">requests</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mRunUsage\u001b[0m\u001b[1m(\u001b[0m\u001b[33minput_tokens\u001b[0m=\u001b[1;36m8\u001b[0m, \u001b[33moutput_tokens\u001b[0m=\u001b[1;36m14\u001b[0m, \u001b[33mdetails\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'reasoning_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'image_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mrequests\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.openrouter import OpenRouterProvider\n",
    "\n",
    "\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "model = OpenAIChatModel(\n",
    "    'google/gemini-2.5-flash-lite',\n",
    "    provider=OpenRouterProvider(api_key=OPENROUTER_API_KEY),\n",
    "    system_prompt_role=\"system\",\n",
    ")\n",
    "agent = Agent(model,    model_settings={\"temperature\": 0})\n",
    "result = await agent.run('Tell me a joke about programmers.')\n",
    "print(result.output)\n",
    "print(result.usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why do programmers prefer dark mode?\n",
       "\n",
       "Because light attracts bugs.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why do programmers prefer dark mode?\n",
       "\n",
       "Because light attracts bugs.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunUsage</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">input_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">output_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>, <span style=\"color: #808000; text-decoration-color: #808000\">requests</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mRunUsage\u001b[0m\u001b[1m(\u001b[0m\u001b[33minput_tokens\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33moutput_tokens\u001b[0m=\u001b[1;36m13\u001b[0m, \u001b[33mrequests\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.ollama import OllamaProvider\n",
    "\n",
    "ollama_model = OpenAIChatModel(\n",
    "    model_name='llama3.2',\n",
    "    provider=OllamaProvider(base_url='http://eos.local:11434/v1'), \n",
    "    settings={\"temperature\": 0, \"max_tokens\": 1000} \n",
    ")\n",
    "agent = Agent(ollama_model)\n",
    "\n",
    "result = await agent.run('Tell me a joke about programmers.')\n",
    "print(result.output)\n",
    "#> city='London' country='United Kingdom'\n",
    "print(result.usage())\n",
    "#> RunUsage(input_tokens=57, output_tokens=8, requests=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Data Models with Pydantic AI\n",
    "\n",
    "- Pydantic AI allows you to define data models using Python classes. These models are used to validate and parse input data.\n",
    "- In this example, we define a `User` model with fields for `name`, `age`, and `occupation`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e686a3aa-8586-43ef-9d5f-ca2963650044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define Your Desired Data Structure ---\n",
    "# Imagine you have unstructured text and you want to pull out specific, clean\n",
    "# information. With Pydantic, you define a class that represents the \"shape\" of the data you want.\n",
    "# This gives you type-safety and auto-validation out of the box.\n",
    "class User(BaseModel):\n",
    "    \"\"\"A Pydantic model to represent a user's information.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"The user's full name\")\n",
    "    age: int = Field(description=\"The user's age in years\")\n",
    "    role: str = Field(description=\"The user's role or job title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Agent with Data Models\n",
    "\n",
    "- We can use the agent to parse unstructured text and extract structured data according to our User model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">User</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Alice'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">age</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>, <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'software engineer'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mUser\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'Alice'\u001b[0m, \u001b[33mage\u001b[0m=\u001b[1;36m30\u001b[0m, \u001b[33mrole\u001b[0m=\u001b[32m'software engineer'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent(model,output_type=User)\n",
    "# --- Use the Agent to Parse Unstructured Text ---\n",
    "prompt = \"Alice is a 30-year-old software engineer.\"\n",
    "result = await agent.run(prompt) # output_type=User can be set in run or in Agent\n",
    "print(result.output)\n",
    "print(result.usage())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
